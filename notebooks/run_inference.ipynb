{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facemap Pose Estimation -- Run Inference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import datajoint as dj\n",
    "import os\n",
    "\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "dj.config.load('dj_local_conf.json')\n",
    "\n",
    "from workflow.pipeline import *\n",
    "from workflow.utils.ingest import ingest_model, generate_facemap_pose_estimation_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Subject and Session into subject.Subject, session.Session and session.SessionDirectory tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_insert = dict(subject=\"mdl_sub\", \n",
    "                subject_nickname=\"facemap model subject\", \n",
    "                sex='U', \n",
    "                subject_birth_date=datetime.datetime.now(), \n",
    "                subject_description=\"Subject for Facemap Model Inference testing\")\n",
    "# subject.Subject.insert1(sub_insert)\n",
    "subject_key = (subject.Subject & 'subject=\"mdl_sub\"').fetch1(\"KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = 2\n",
    "session_insert = dict(subject_key, session_id, session_datetime=datetime.datetime.now())\n",
    "sdir_insert = dict(subject_key, session_id, session_dir=\"20230627_Image_eCBsensor_activity/Behavior_20230627/C57-C11-3_Rm_CNO_30min\")\n",
    "\n",
    "session.Session.insert1(session_insert)\n",
    "session.SessionDirectory.insert1(sdir_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Session Table to validate insert\n",
    "session.Session() & {**subject_key, 'session_id': session_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display SessionDirectory Table to validate insert\n",
    "session.SessionDirectory() & {**subject_key, 'session_id': session_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest locally stored pytorch model(.pt) file\n",
    "Provide model name, model filepath, and optional model description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'facemap_model_state.pt'\n",
    "full_local_model_filepath = \"/Users/sidhulyalkar/.facemap/models/facemap_model_state.pt\"\n",
    "ingest_model(model_name, model_description=\"test facemap model\", model_file=full_local_model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a Pose Estimation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 0\n",
    "session_key = session.Session.fetch(\"KEY\")[2] \n",
    "generate_facemap_pose_estimation_task(model_id, session_key, task_mode=\"trigger\", bbox=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display FacemapPoseEstimationTask table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facemap_pose.FacemapPoseEstimationTask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display VideoRecording and VideoRecording.File tables from the imported facial behavioral estimation (fbe) schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbe.VideoRecording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbe.VideoRecording.File()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Pose Estimation on all unprocessed FacemapPoseEstimationTasks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facemap_pose.FacemapPoseEstimation.populate(display_progress=True)\n",
    "# If a lost connection error occurs, rerun the populate and if processing \n",
    "# has completed, the data will be loaded and inference will not be rerun. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Facemap Pose Estimation Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facemap_pose.FacemapPoseEstimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facemap_pose.FacemapPoseEstimation.BodyPartPosition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Pose Estimation Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_query = {**session_key, 'recording_id': 0, 'model_id': model_id}\n",
    "pose_estimation_key = (facemap_pose.FacemapPoseEstimation & pe_query).fetch1(\"KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Trajectory of X and Y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify all body parts, or set body_parts to a custom list\n",
    "body_parts = \"all\"\n",
    "model_name = (facemap_pose.FacemapModel & f'model_id={key[\"model_id\"]}').fetch1(\"model_name\")\n",
    "\n",
    "if body_parts == \"all\":\n",
    "    body_parts = (facemap_pose.BodyPartPosition & key).fetch(\"body_part\")\n",
    "elif not isinstance(body_parts, list):\n",
    "    body_parts = list(body_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Pandas MultiIndex DataFrame\n",
    "df = None\n",
    "for body_part in body_parts:\n",
    "    result_dict = (\n",
    "        facemap_pose.BodyPartPosition\n",
    "        & {\"body_part\": body_part}\n",
    "        & {\"recording_id\": key[\"recording_id\"]}\n",
    "        & {\"session_id\": key[\"session_id\"]}\n",
    "    ).fetch(\"x_pos\", \"y_pos\", \"likelihood\", as_dict=True)[0]\n",
    "    x_pos = result_dict[\"x_pos\"].tolist()\n",
    "    y_pos = result_dict[\"y_pos\"].tolist()\n",
    "    likelihood = result_dict[\"likelihood\"].tolist()\n",
    "    a = np.vstack((x_pos, y_pos, likelihood))\n",
    "    a = a.T\n",
    "    pdindex = pd.MultiIndex.from_product(\n",
    "        [[model_name], [body_part], [\"x\", \"y\", \"likelihood\"]],\n",
    "        names=[\"model\", \"bodyparts\", \"coords\"],\n",
    "    )\n",
    "    frame = pd.DataFrame(a, columns=pdindex, index=range(0, a.shape[0]))\n",
    "    df = pd.concat([df, frame], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or can use the built in function get_trajectory which also constructs this Pandas MultiIndex DataFrame\n",
    "# df=facemap_pose.FacemapPoseEstimation.get_trajectory(pose_estimation_key)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xy = df.iloc[:,df.columns.get_level_values(2).isin([\"x\",\"y\"])]['facemap_model_state.pt']\n",
    "df_xy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot coordinates across time for each body part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xy.plot().legend(loc='best', prop={'size': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat = df_xy.copy()\n",
    "df_flat.columns = df_flat.columns.map('_'.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Trace Overlays of each body part across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig,ax=plt.subplots(2,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(15)\n",
    "\n",
    "df_flat.plot(x='eye(front)_x',y='eye(front)_y',ax=ax[0, 0])\n",
    "df_flat.plot(x='eye(back)_x',y='eye(back)_y',ax=ax[0, 0])\n",
    "df_flat.plot(x='eye(bottom)_x',y='eye(bottom)_y',ax=ax[0, 0])\n",
    "\n",
    "df_flat.plot(x='nose(tip)_x',y='nose(tip)_y', ax=ax[1, 0])\n",
    "df_flat.plot(x='nose(bottom)_x',y='nose(bottom)_y', ax=ax[1, 0])\n",
    "df_flat.plot(x='nose(r)_x',y='nose(r)_y', ax=ax[1, 0])\n",
    "df_flat.plot(x='nosebridge_x',y='nosebridge_y', ax=ax[1, 0])\n",
    "\n",
    "df_flat.plot(x='mouth_x',y='mouth_y', ax=ax[0, 1])\n",
    "df_flat.plot(x='lowerlip_x',y='lowerlip_y', ax=ax[0, 1])\n",
    "df_flat.plot(x='paw_x',y='paw_y', ax=ax[0, 1])\n",
    "\n",
    "df_flat.plot(x='whisker(I)_x',y='whisker(I)_y', ax=ax[1, 1])\n",
    "df_flat.plot(x='whisker(II)_x',y='whisker(II)_y', ax=ax[1, 1])\n",
    "df_flat.plot(x='whisker(II)_x',y='whisker(II)_y', ax=ax[1, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
